{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1b88a3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e9bf2996",
      "metadata": {},
      "source": [
        "# 서울시 요식업 평균 매출 예측 모델\n",
        "\n",
        "저희 팀은 서울시 요식업 매출 데이터를 분석하고 예측 모델을 구축했습니다. 창업 의사결정에 도움이 될 수 있는 인사이트를 제공하고자 했습니다."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89c0db4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os, gc, joblib\n",
        "from pathlib import Path\n",
        "\n",
        "plt.rc('font', family='Malgun Gothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a52139",
      "metadata": {},
      "source": [
        "## 1. 데이터 로딩과 전처리"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ecf888a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"데이터 로드 및 전처리 중...\")\n",
        "# 디렉토리 생성\n",
        "Path('plots').mkdir(exist_ok=True)\n",
        "Path('models').mkdir(exist_ok=True)\n",
        "\n",
        "# 데이터 로드\n",
        "sales_df = pd.read_csv(\"data/서울시 상권분석서비스(추정매출-상권).csv\", encoding=\"cp949\")\n",
        "work_df = pd.read_csv(\"data/서울시 상권분석서비스(직장인구-상권).csv\", encoding=\"cp949\")\n",
        "street_df = pd.read_csv(\"data/서울시 상권분석서비스(길단위인구-상권).csv\", encoding=\"cp949\")\n",
        "\n",
        "# 요식업 데이터만 필터링 (CS1 코드)\n",
        "restaurant_sales = sales_df[sales_df[\"서비스_업종_코드\"].str.startswith(\"CS1\")].copy()\n",
        "\n",
        "# 데이터 전처리 함수 - 문자열을 숫자로 변환\n",
        "def convert_to_numeric(df):\n",
        "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "# 전처리 적용\n",
        "restaurant_sales = convert_to_numeric(restaurant_sales)\n",
        "work_df = convert_to_numeric(work_df)\n",
        "street_df = convert_to_numeric(street_df)\n",
        "\n",
        "# 평균매출 계산 (main.py 방식으로 변경)\n",
        "grouped = restaurant_sales.groupby([\"상권_코드_명\", \"기준_년분기_코드\"])[[\"당월_매출_금액\"]].mean().reset_index()\n",
        "grouped.rename(columns={\"당월_매출_금액\": \"평균매출\"}, inplace=True)\n",
        "\n",
        "# 인구 데이터 병합\n",
        "merged = pd.merge(grouped, street_df, on=[\"상권_코드_명\", \"기준_년분기_코드\"], how=\"left\")\n",
        "merged = pd.merge(merged, work_df, on=[\"상권_코드_명\", \"기준_년분기_코드\"], how=\"left\")\n",
        "\n",
        "# 상권 구분 코드 병합\n",
        "duplicate_drop = sales_df[[\"상권_코드_명\", \"상권_구분_코드_명\"]].drop_duplicates()\n",
        "restaurant_data = pd.merge(merged, duplicate_drop, on=\"상권_코드_명\", how=\"left\")\n",
        "\n",
        "# 결측치 처리\n",
        "# 수치형 컬럼 - 중앙값으로 대체\n",
        "numeric_cols = restaurant_data.select_dtypes(include=['number']).columns\n",
        "for col in numeric_cols:\n",
        "    if restaurant_data[col].isnull().any():\n",
        "        restaurant_data[col] = restaurant_data[col].fillna(restaurant_data[col].median())\n",
        "\n",
        "# 문자열 컬럼 - 최빈값으로 대체\n",
        "object_cols = restaurant_data.select_dtypes(include=['object']).columns\n",
        "for col in object_cols:\n",
        "    if restaurant_data[col].isnull().any():\n",
        "        restaurant_data[col] = restaurant_data[col].fillna(restaurant_data[col].mode().iloc[0] if not restaurant_data[col].mode().empty else \"알수없음\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8fa97b4",
      "metadata": {},
      "source": [
        "## 2. 특성 엔지니어링"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c62e888",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"특성 엔지니어링 중...\")\n",
        "\n",
        "# 연령대별 인구 통합 (필요한 Feature만 생성)\n",
        "restaurant_data[\"초년_유동인구_수\"] = restaurant_data[\"연령대_10_유동인구_수\"] + restaurant_data[\"연령대_20_유동인구_수\"]\n",
        "restaurant_data[\"중년_유동인구_수\"] = restaurant_data[\"연령대_30_유동인구_수\"] + restaurant_data[\"연령대_40_유동인구_수\"]\n",
        "restaurant_data[\"노년_유동인구_수\"] = restaurant_data[\"연령대_50_유동인구_수\"] + restaurant_data[\"연령대_60_이상_유동인구_수\"]\n",
        "restaurant_data[\"초년_직장_인구_수\"] = restaurant_data[\"연령대_10_직장_인구_수\"] + restaurant_data[\"연령대_20_직장_인구_수\"]\n",
        "restaurant_data[\"중년_직장_인구_수\"] = restaurant_data[\"연령대_30_직장_인구_수\"] + restaurant_data[\"연령대_40_직장_인구_수\"]\n",
        "restaurant_data[\"노년_직장_인구_수\"] = restaurant_data[\"연령대_50_직장_인구_수\"] + restaurant_data[\"연령대_60_이상_직장_인구_수\"]\n",
        "\n",
        "# 필요한 컬럼만 선택\n",
        "keep_cols = [\n",
        "    \"기준_년분기_코드\", \"상권_코드_명\", \"상권_구분_코드_명\", \"평균매출\",\n",
        "    \"총_유동인구_수\", \"남성_유동인구_수\", \"여성_유동인구_수\", \n",
        "    \"총_직장_인구_수\", \"남성_직장_인구_수\", \"여성_직장_인구_수\",\n",
        "    \"초년_유동인구_수\", \"중년_유동인구_수\", \"노년_유동인구_수\", \n",
        "    \"초년_직장_인구_수\", \"중년_직장_인구_수\", \"노년_직장_인구_수\"\n",
        "]\n",
        "restaurant_data = restaurant_data[keep_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03625f4",
      "metadata": {},
      "source": [
        "## 3. 전처리 파이프라인 구성"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1166361b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"전처리 파이프라인 구성 중...\")\n",
        "\n",
        "# 모델링용 특성 정의 - 범주형 변수와 수치형 변수 구분\n",
        "categorical_features = [\"상권_구분_코드_명\"]\n",
        "numeric_features = [\n",
        "    \"총_유동인구_수\", \"남성_유동인구_수\", \"여성_유동인구_수\", \n",
        "    \"총_직장_인구_수\", \"남성_직장_인구_수\", \"여성_직장_인구_수\", \n",
        "    \"초년_유동인구_수\", \"중년_유동인구_수\", \"노년_유동인구_수\", \n",
        "    \"초년_직장_인구_수\", \"중년_직장_인구_수\", \"노년_직장_인구_수\"\n",
        "]\n",
        "\n",
        "# 전처리 파이프라인 구성\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# 데이터 준비 - 특성과 타겟 분리\n",
        "X = restaurant_data[numeric_features + categorical_features]\n",
        "y = restaurant_data[\"평균매출\"]\n",
        "\n",
        "# 파이프라인으로 데이터 변환 (전체 데이터)\n",
        "preprocessor.fit(X)\n",
        "X_transformed = preprocessor.transform(X)\n",
        "\n",
        "# 변환된 특성 이름 추출\n",
        "transformed_feature_names = numeric_features.copy()\n",
        "\n",
        "# 범주형 특성의 원핫인코딩된 이름 추출\n",
        "cat_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "if hasattr(cat_encoder, 'get_feature_names_out'):\n",
        "    categorical_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
        "    transformed_feature_names.extend(categorical_feature_names)\n",
        "else:\n",
        "    # 원래 카테고리 이름 + 고유값으로 수동 생성 (이전 버전 호환성)\n",
        "    unique_cats = X[categorical_features[0]].unique()\n",
        "    for cat in unique_cats:\n",
        "        transformed_feature_names.append(f\"{categorical_features[0]}_{cat}\")\n",
        "\n",
        "# 변환된 데이터를 DataFrame으로 변환\n",
        "transformed_df = pd.DataFrame(X_transformed, columns=transformed_feature_names)\n",
        "transformed_df[\"평균매출\"] = y  # 타겟 변수 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78857cea",
      "metadata": {},
      "source": [
        "## 4. 특성 간 상관관계 분석"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e374764",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"특성 간 상관관계 분석 중...\")\n",
        "\n",
        "# 변환된 데이터로 상관계수 계산\n",
        "correlation_matrix = transformed_df.corr()\n",
        "\n",
        "# 평균매출과의 상관계수 내림차순 정렬\n",
        "correlation_with_target = correlation_matrix['평균매출'].sort_values(ascending=False)\n",
        "\n",
        "# 상관계수 출력\n",
        "print(\"\\n평균 매출과 상관관계가 높은 특성 (상위 15개):\")\n",
        "print(correlation_with_target.head(15))\n",
        "\n",
        "# 상관계수 히트맵 시각화 - 너무 많은 특성이 있을 경우, 상위 15개만 시각화\n",
        "top_features = correlation_with_target.index[:15]\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(correlation_matrix.loc[top_features, top_features], annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('특성 간 상관계수 히트맵 (상위 15개)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('plots/correlation_heatmap.png')\n",
        "plt.close()\n",
        "\n",
        "# 다중공선성 확인 (상관계수가 0.8 이상인 특성 쌍 찾기)\n",
        "high_correlation_pairs = []\n",
        "numeric_only_features = [col for col in transformed_feature_names if col in numeric_features]\n",
        "\n",
        "for i in range(len(numeric_only_features)):\n",
        "    for j in range(i+1, len(numeric_only_features)):\n",
        "        feature_i = numeric_only_features[i]\n",
        "        feature_j = numeric_only_features[j]\n",
        "        corr = correlation_matrix.loc[feature_i, feature_j]\n",
        "        if abs(corr) > 0.8:\n",
        "            high_correlation_pairs.append((feature_i, feature_j, corr))\n",
        "\n",
        "# 다중공선성 출력\n",
        "if high_correlation_pairs:\n",
        "    print(\"\\n다중공선성이 높은 특성 쌍 (상관계수 > 0.8):\")\n",
        "    for feature_i, feature_j, corr in high_correlation_pairs:\n",
        "        print(f\"- {feature_i} 와 {feature_j}: {corr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df252b1d",
      "metadata": {},
      "source": [
        "## 5. 모델 훈련 및 평가"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2ae35e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"모델 훈련 및 평가 중...\")\n",
        "\n",
        "# 데이터 분할 - 원본 데이터 사용\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 정의\n",
        "models = {\n",
        "    'Linear Regression': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]),\n",
        "    'Ridge': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', Ridge(alpha=1.0))\n",
        "    ]),\n",
        "    'Lasso': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', Lasso(alpha=0.1))\n",
        "    ]),\n",
        "    'Random Forest': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42))\n",
        "    ]),\n",
        "    'Gradient Boosting': Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# 모델 평가 결과 저장\n",
        "results = []\n",
        "\n",
        "# 모델 훈련 및 평가\n",
        "for name, model in models.items():\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # 교차 검증 점수 - 여러 지표로 확장\n",
        "    cv_rmse_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
        "    cv_rmse = -cv_rmse_scores.mean()\n",
        "    cv_rmse_std = cv_rmse_scores.std()\n",
        "    \n",
        "    cv_mae_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
        "    cv_mae = -cv_mae_scores.mean()\n",
        "    \n",
        "    cv_r2_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "    cv_r2 = cv_r2_scores.mean()\n",
        "    \n",
        "    # 예측 및 평가\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    test_mae = mean_absolute_error(y_test, y_pred)\n",
        "    test_r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    # 과적합 계산 - 학습과 테스트 오차의 차이\n",
        "    overfitting_rmse = (train_rmse - test_rmse) / train_rmse * 100 if train_rmse > 0 else 0\n",
        "    overfitting_r2 = (train_r2 - test_r2) / train_r2 * 100 if train_r2 > 0 else 0\n",
        "    \n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Train RMSE': train_rmse,\n",
        "        'Train MAE': train_mae,\n",
        "        'Train R2': train_r2,\n",
        "        'CV RMSE': cv_rmse,\n",
        "        'CV RMSE STD': cv_rmse_std,\n",
        "        'CV MAE': cv_mae,\n",
        "        'CV R2': cv_r2,\n",
        "        'Test RMSE': test_rmse,\n",
        "        'Test MAE': test_mae,\n",
        "        'Test R2': test_r2,\n",
        "        'RMSE Overfitting (%)': overfitting_rmse,\n",
        "        'R2 Overfitting (%)': overfitting_r2\n",
        "    })\n",
        "    \n",
        "    print(f\"- {name}: Train RMSE={train_rmse:.2f}, Test RMSE={test_rmse:.2f}, CV RMSE={cv_rmse:.2f}±{cv_rmse_std:.2f}\")\n",
        "    print(f\"  R2 (Train/CV/Test)={train_r2:.3f}/{cv_r2:.3f}/{test_r2:.3f}\")\n",
        "\n",
        "# 결과 정렬\n",
        "results_df = pd.DataFrame(results).sort_values('Test RMSE')\n",
        "\n",
        "# 학습, CV, 테스트 지표 모두 출력 - 컬럼 순서 정렬\n",
        "print(\"\\n모델 평가 결과 (테스트 RMSE 기준 정렬):\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(results_df[[\n",
        "    'Model', \n",
        "    'Train RMSE', 'CV RMSE', 'Test RMSE',\n",
        "    'Train MAE', 'CV MAE', 'Test MAE', \n",
        "    'Train R2', 'CV R2', 'Test R2',\n",
        "    'CV RMSE STD', 'RMSE Overfitting (%)', 'R2 Overfitting (%)'\n",
        "]])\n",
        "\n",
        "# 학습-테스트 성능 격차 시각화\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "models_list = results_df['Model'].tolist()\n",
        "train_rmse_list = results_df['Train RMSE'].tolist()\n",
        "cv_rmse_list = results_df['CV RMSE'].tolist()\n",
        "test_rmse_list = results_df['Test RMSE'].tolist()\n",
        "\n",
        "x = np.arange(len(models_list))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, train_rmse_list, width, label='Train RMSE')\n",
        "plt.bar(x, cv_rmse_list, width, label='CV RMSE')\n",
        "plt.bar(x + width, test_rmse_list, width, label='Test RMSE')\n",
        "\n",
        "plt.xlabel('모델')\n",
        "plt.ylabel('RMSE')\n",
        "plt.title('모델별 학습, 교차검증, 테스트 RMSE 비교')\n",
        "plt.xticks(x, models_list, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# R2 비교 추가\n",
        "plt.subplot(2, 1, 2)\n",
        "train_r2_list = results_df['Train R2'].tolist()\n",
        "cv_r2_list = results_df['CV R2'].tolist()\n",
        "test_r2_list = results_df['Test R2'].tolist()\n",
        "\n",
        "plt.bar(x - width, train_r2_list, width, label='Train R²')\n",
        "plt.bar(x, cv_r2_list, width, label='CV R²')\n",
        "plt.bar(x + width, test_r2_list, width, label='Test R²')\n",
        "\n",
        "plt.xlabel('모델')\n",
        "plt.ylabel('R²')\n",
        "plt.title('모델별 학습, 교차검증, 테스트 R² 비교')\n",
        "plt.xticks(x, models_list, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('plots/model_performance_comparison.png')\n",
        "plt.close()\n",
        "\n",
        "# 과적합 분석\n",
        "overfitting_threshold = 30  # 30% 이상 차이나면 과적합 의심\n",
        "overfitting_models = results_df[results_df['RMSE Overfitting (%)'] > overfitting_threshold]\n",
        "if not overfitting_models.empty:\n",
        "    print(\"\\n주의: 다음 모델에서 과적합 가능성이 있습니다:\")\n",
        "    for idx, row in overfitting_models.iterrows():\n",
        "        print(f\"- {row['Model']}: 학습 RMSE가 테스트 RMSE보다 {row['RMSE Overfitting (%)']:.1f}% 낮습니다.\")\n",
        "\n",
        "# RandomForest 모델 최적화 (성능이 가장 좋은 모델)\n",
        "print(\"\\nRandomForest 모델 최적화 중...\")\n",
        "rf_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "rf_params = {\n",
        "    'regressor__n_estimators': [100, 200],\n",
        "    'regressor__max_depth': [None, 10, 20],\n",
        "    'regressor__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "rf_gs = GridSearchCV(rf_pipeline, rf_params, cv=5, n_jobs=-1, \n",
        "                    scoring={'rmse': 'neg_root_mean_squared_error', \n",
        "                             'mae': 'neg_mean_absolute_error',\n",
        "                             'r2': 'r2'},\n",
        "                    refit='rmse')\n",
        "rf_gs.fit(X_train, y_train)\n",
        "print(\"최적 RandomForest 파라미터:\", rf_gs.best_params_)\n",
        "best_rf = rf_gs.best_estimator_\n",
        "\n",
        "# 최적화된 모델의 학습 및 테스트 성능 비교 - 통합된 평가 지표 사용\n",
        "print(\"\\n최적화된 RandomForest 모델 평가:\")\n",
        "\n",
        "# 교차 검증 성능\n",
        "cv_rmse_best = -rf_gs.cv_results_['mean_test_rmse'][rf_gs.best_index_]\n",
        "cv_mae_best = -rf_gs.cv_results_['mean_test_mae'][rf_gs.best_index_]\n",
        "cv_r2_best = rf_gs.cv_results_['mean_test_r2'][rf_gs.best_index_]\n",
        "\n",
        "# 학습 데이터 성능\n",
        "y_train_pred_best = best_rf.predict(X_train)\n",
        "train_rmse_best = np.sqrt(mean_squared_error(y_train, y_train_pred_best))\n",
        "train_mae_best = mean_absolute_error(y_train, y_train_pred_best)\n",
        "train_r2_best = r2_score(y_train, y_train_pred_best)\n",
        "\n",
        "# 테스트 데이터 성능\n",
        "y_test_pred_best = best_rf.predict(X_test)\n",
        "test_rmse_best = np.sqrt(mean_squared_error(y_test, y_test_pred_best))\n",
        "test_mae_best = mean_absolute_error(y_test, y_test_pred_best)\n",
        "test_r2_best = r2_score(y_test, y_test_pred_best)\n",
        "\n",
        "# 과적합 계산\n",
        "overfitting_rmse_best = (train_rmse_best - test_rmse_best) / train_rmse_best * 100 if train_rmse_best > 0 else 0\n",
        "overfitting_r2_best = (train_r2_best - test_r2_best) / train_r2_best * 100 if train_r2_best > 0 else 0\n",
        "\n",
        "# 결과 출력 - 테이블 형식\n",
        "best_model_results = pd.DataFrame({\n",
        "    'Metric': ['RMSE', 'MAE', 'R²', 'Overfitting (%)'],\n",
        "    'Train': [train_rmse_best, train_mae_best, train_r2_best, '-'],\n",
        "    'CV': [cv_rmse_best, cv_mae_best, cv_r2_best, '-'],\n",
        "    'Test': [test_rmse_best, test_mae_best, test_r2_best, '-'],\n",
        "    'Train-Test': [f\"{train_rmse_best-test_rmse_best:.2f}\", \n",
        "                  f\"{train_mae_best-test_mae_best:.2f}\", \n",
        "                  f\"{train_r2_best-test_r2_best:.4f}\",\n",
        "                  f\"RMSE: {overfitting_rmse_best:.1f}%, R²: {overfitting_r2_best:.1f}%\"]\n",
        "})\n",
        "\n",
        "print(best_model_results)\n",
        "\n",
        "# 과적합 경고\n",
        "if overfitting_rmse_best > overfitting_threshold:\n",
        "    print(f\"\\n주의: 최적화된 모델에서 과적합이 발생했을 수 있습니다. (RMSE 차이: {overfitting_rmse_best:.1f}%)\")\n",
        "    print(\"정규화 매개변수를 조정하거나 특성 선택을 다시 검토해 보세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9dc759e",
      "metadata": {},
      "source": [
        "## 6. 최적 모델 분석 및 특성 중요도"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08981e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"최적 모델 분석 중...\")\n",
        "\n",
        "# 최적 모델로 최종 예측\n",
        "y_pred = best_rf.predict(X_test)\n",
        "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "final_r2 = r2_score(y_test, y_pred)\n",
        "final_mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"최종 모델 성능: RMSE={final_rmse:.2f}, R2={final_r2:.3f}, MAE={final_mae:.2f}\")\n",
        "\n",
        "# 특성 중요도 추출\n",
        "rf_importances = best_rf.named_steps['regressor'].feature_importances_\n",
        "\n",
        "# 특성 중요도 데이터프레임 생성\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': transformed_feature_names[:len(rf_importances)],  # 길이 맞추기\n",
        "    'importance': rf_importances\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n특성 중요도 (상위 10개):\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# 특성 중요도 시각화\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='importance', y='feature', data=importance_df.head(10))\n",
        "plt.title('상위 10개 중요 특성')\n",
        "plt.tight_layout()\n",
        "plt.savefig('plots/feature_importance.png')\n",
        "plt.close()\n",
        "\n",
        "# 모델 저장\n",
        "joblib.dump(best_rf, 'models/random_forest_model.pkl')\n",
        "print(\"모델 저장 완료\")\n",
        "\n",
        "# 최종 정제된 데이터 저장\n",
        "restaurant_data.to_csv(\"data/서울시_요식업_정제데이터.csv\", index=False, encoding=\"cp949\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a763597b",
      "metadata": {},
      "source": [
        "## 7. 예측 결과 및 결론"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59adde73",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n예측 결과 및 결론:\")\n",
        "print(f\"- RandomForest 모델이 R² = {final_r2:.4f}로 가장 우수한 성능을 보였습니다.\")\n",
        "print(\"- 상관관계 분석을 통해 직장인구와 유동인구 특성이 매출에 미치는 영향을 확인했습니다.\")\n",
        "print(\"- 특성 중요도 분석 결과, 중년 직장인구 수와 총 직장인구 수가 매출에 가장 큰 영향을 미쳤습니다.\")\n",
        "print(\"- 상권 유형별 매출 차이도 중요한 요소로 확인되었습니다.\")\n",
        "print(\"- 창업 위치 선정 시 유동인구보다 직장인구 특성을 더 중요하게 고려해야 합니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da5f155e-9ae2-4366-881b-a2903f7de644",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0503c411-ebbf-497b-a0f6-4d92b2c19302",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
